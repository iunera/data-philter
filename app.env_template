# Philter Server settings

SERVER_PORT=4000

# IUNERA_MODEL_TYPE
#
# Specifies the AI model to be used by the application, based on the Aura model tier system.
# Each tier is fine-tuned for specific use cases, from complex reasoning to simple pattern-matching.
#
# Possible values are:
#
#   - "ollama-s" (Small Tier) The Reliable Agent:
#     - Model: iunera/aura-s (based on Microsoft Phi-4-mini, 3.8B parameters)
#     - Use Case: The default agent for simple, clear, single-intent instructions. A good "all-rounder."
#     - Details: https://ollama.com/iunera/aura-s
#
#   - "ollama-m" (Medium Tier) The Reasoning Workhorse:
#     - Model: iunera/aura-m (based on Dolphin Llama 3.1, 8B parameters)
#     - Use Case: Your primary "workhorse" model for complex, multi-step tasks and conversations that require chat history context.
#     - Requires: A GPU-based system or a Macbook with an M-series chip and at least 8GB of memory.
#     - Details: https://ollama.com/iunera/aura-m
#
#   - "ollama-l" (Large Model):
#     - Uses the iunera/aura-l Model which is based on Microsoft phi4-reasoning 14b model.
#     - A more powerful model with advanced reasoning capabilities, recommended for complex queries and production environments.
#     - Requires a GPU-based system or a Macbook with an M-series chip and at least 8GB of memory.
#     - Model details: https://ollama.com/iunera/aura-l
#
#   - "ollama-xl" (Extra Large Model):
#     - Uses the gpt-oss:20b model.
#     - Recommended for heavy workloads and advanced reasoning on capable hardware.
#     - Recommended on a Macbook with an Apple Mâ€‘series chip and at least 64GB of unified memory (or strong GPU setup).
#
#   - "openai" (OpenAI Model):
#     - Uses the OpenAI API to access their models.
#     - Requires an OpenAI API key to be set in the SPRING_AI_OPENAI_API_KEY variable.
#

IUNERA_MODEL_TYPE=

# SPRING_AI_OPENAI_API_KEY
#
# Your OpenAI API key. Required only when IUNERA_MODEL_TYPE is set to "openai".
SPRING_AI_OPENAI_API_KEY=

# SPRING_AI_OLLAMA_BASE_URL
#
# The base URL for your Ollama server instance. Adjust if you have Ollama running on a different host.
# Default is http://host.docker.internal:11434
SPRING_AI_OLLAMA_BASE_URL=http://host.docker.internal:11434
